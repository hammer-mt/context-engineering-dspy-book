{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e651f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dspy\n",
      "  Using cached dspy-3.0.3-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting backoff>=2.2 (from dspy)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting joblib~=1.3 (from dspy)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting openai>=0.28.1 (from dspy)\n",
      "  Downloading openai-2.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting regex>=2023.10.3 (from dspy)\n",
      "  Using cached regex-2025.9.18-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting orjson>=3.9.0 (from dspy)\n",
      "  Using cached orjson-3.11.3-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting tqdm>=4.66.1 (from dspy)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting requests>=2.31.0 (from dspy)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting optuna>=3.4.0 (from dspy)\n",
      "  Using cached optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pydantic>=2.0 (from dspy)\n",
      "  Using cached pydantic-2.12.0-py3-none-any.whl.metadata (83 kB)\n",
      "Collecting magicattr>=0.1.6 (from dspy)\n",
      "  Using cached magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting litellm>=1.64.0 (from dspy)\n",
      "  Downloading litellm-1.78.0-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting diskcache>=5.6.0 (from dspy)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting json-repair>=0.30.0 (from dspy)\n",
      "  Using cached json_repair-0.52.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tenacity>=8.2.3 (from dspy)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyio (from dspy)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting asyncer==0.0.8 (from dspy)\n",
      "  Using cached asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting cachetools>=5.5.0 (from dspy)\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting cloudpickle>=3.0.0 (from dspy)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting rich>=13.7.1 (from dspy)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting numpy>=1.26.0 (from dspy)\n",
      "  Using cached numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting xxhash>=3.5.0 (from dspy)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting gepa==0.0.7 (from gepa[dspy]==0.0.7->dspy)\n",
      "  Using cached gepa-0.0.7-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting idna>=2.8 (from anyio->dspy)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->dspy)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting aiohttp>=3.10 (from litellm>=1.64.0->dspy)\n",
      "  Using cached aiohttp-3.13.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting click (from litellm>=1.64.0->dspy)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fastuuid>=0.13.0 (from litellm>=1.64.0->dspy)\n",
      "  Using cached fastuuid-0.13.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (1.0 kB)\n",
      "Collecting httpx>=0.23.0 (from litellm>=1.64.0->dspy)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm>=1.64.0->dspy)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting jinja2<4.0.0,>=3.1.2 (from litellm>=1.64.0->dspy)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm>=1.64.0->dspy)\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting python-dotenv>=0.2.0 (from litellm>=1.64.0->dspy)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken>=0.7.0 (from litellm>=1.64.0->dspy)\n",
      "  Using cached tiktoken-0.12.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting tokenizers (from litellm>=1.64.0->dspy)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy)\n",
      "  Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy)\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy)\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy)\n",
      "  Using cached rpds_py-0.27.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->dspy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.1 (from pydantic>=2.0->dspy)\n",
      "  Using cached pydantic_core-2.41.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-extensions>=4.14.1 (from pydantic>=2.0->dspy)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.0->dspy)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10->litellm>=1.64.0->dspy)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp>=3.10->litellm>=1.64.0->dspy)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.10->litellm>=1.64.0->dspy)\n",
      "  Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10->litellm>=1.64.0->dspy)\n",
      "  Using cached multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.10->litellm>=1.64.0->dspy)\n",
      "  Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10->litellm>=1.64.0->dspy)\n",
      "  Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting certifi (from httpx>=0.23.0->litellm>=1.64.0->dspy)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->litellm>=1.64.0->dspy)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=0.28.1->dspy)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=0.28.1->dspy)\n",
      "  Using cached jiter-0.11.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.4.0->dspy)\n",
      "  Downloading alembic-1.17.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting colorlog (from optuna>=3.4.0->dspy)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hammermt/Codes/dspy-book/.venv/lib/python3.13/site-packages (from optuna>=3.4.0->dspy) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna>=3.4.0->dspy)\n",
      "  Downloading sqlalchemy-2.0.44-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting PyYAML (from optuna>=3.4.0->dspy)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna>=3.4.0->dspy)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.31.0->dspy)\n",
      "  Using cached charset_normalizer-3.4.3-cp313-cp313-macosx_10_13_universal2.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->dspy)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->dspy)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/hammermt/Codes/dspy-book/.venv/lib/python3.13/site-packages (from rich>=13.7.1->dspy) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers->litellm>=1.64.0->dspy)\n",
      "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy)\n",
      "  Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Using cached dspy-3.0.3-py3-none-any.whl (261 kB)\n",
      "Using cached asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
      "Using cached gepa-0.0.7-py3-none-any.whl (52 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached json_repair-0.52.0-py3-none-any.whl (26 kB)\n",
      "Downloading litellm-1.78.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached pydantic-2.12.0-py3-none-any.whl (459 kB)\n",
      "Using cached pydantic_core-2.41.1-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached aiohttp-3.13.0-cp313-cp313-macosx_11_0_arm64.whl (486 kB)\n",
      "Using cached multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached fastuuid-0.13.5-cp313-cp313-macosx_11_0_arm64.whl (244 kB)\n",
      "Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
      "Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Downloading openai-2.3.0-py3-none-any.whl (999 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m999.8/999.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.11.0-cp313-cp313-macosx_11_0_arm64.whl (314 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading alembic-1.17.0-py3-none-any.whl (247 kB)\n",
      "Using cached orjson-3.11.3-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (238 kB)\n",
      "Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Using cached regex-2025.9.18-cp313-cp313-macosx_11_0_arm64.whl (287 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp313-cp313-macosx_10_13_universal2.whl (205 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached rpds_py-0.27.1-cp313-cp313-macosx_11_0_arm64.whl (345 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.12.0-cp313-cp313-macosx_11_0_arm64.whl (993 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: magicattr, zipp, xxhash, urllib3, typing-extensions, tqdm, tenacity, sniffio, rpds-py, regex, PyYAML, python-dotenv, propcache, orjson, numpy, multidict, mdurl, MarkupSafe, json-repair, joblib, jiter, idna, hf-xet, h11, gepa, fsspec, frozenlist, filelock, fastuuid, distro, diskcache, colorlog, cloudpickle, click, charset_normalizer, certifi, cachetools, backoff, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, sqlalchemy, requests, referencing, pydantic-core, markdown-it-py, Mako, jinja2, importlib-metadata, httpcore, anyio, aiosignal, tiktoken, rich, pydantic, jsonschema-specifications, huggingface-hub, httpx, asyncer, alembic, aiohttp, tokenizers, optuna, openai, jsonschema, litellm, dspy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69/69\u001b[0m [dspy]0m [dspy]0m [litellm]ace-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Mako-1.3.10 MarkupSafe-3.0.3 PyYAML-6.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.0 aiosignal-1.4.0 alembic-1.17.0 annotated-types-0.7.0 anyio-4.11.0 asyncer-0.0.8 attrs-25.4.0 backoff-2.2.1 cachetools-6.2.1 certifi-2025.10.5 charset_normalizer-3.4.3 click-8.3.0 cloudpickle-3.1.1 colorlog-6.9.0 diskcache-5.6.3 distro-1.9.0 dspy-3.0.3 fastuuid-0.13.5 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.9.0 gepa-0.0.7 h11-0.16.0 hf-xet-1.1.10 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.35.3 idna-3.11 importlib-metadata-8.7.0 jinja2-3.1.6 jiter-0.11.0 joblib-1.5.2 json-repair-0.52.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 litellm-1.78.0 magicattr-0.1.6 markdown-it-py-4.0.0 mdurl-0.1.2 multidict-6.7.0 numpy-2.3.3 openai-2.3.0 optuna-4.5.0 orjson-3.11.3 propcache-0.4.1 pydantic-2.12.0 pydantic-core-2.41.1 python-dotenv-1.1.1 referencing-0.37.0 regex-2025.9.18 requests-2.32.5 rich-14.2.0 rpds-py-0.27.1 sniffio-1.3.1 sqlalchemy-2.0.44 tenacity-9.1.2 tiktoken-0.12.0 tokenizers-0.22.1 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02dd225e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='The speed of light is 300,000 kilometers per second (km/s).'\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "dspy.configure(lm=dspy.LM(model=\"gpt-4o-mini\"))\n",
    "\n",
    "class QA(dspy.Signature):\n",
    "\t\"\"\"Answer the question as an expert in the topic.\"\"\"\n",
    "\ttopic = dspy.InputField()\n",
    "\tcontext = dspy.InputField()\n",
    "\tquestion = dspy.InputField()\n",
    "\tanswer = dspy.OutputField()\n",
    "\n",
    "\n",
    "predict = dspy.Predict(QA)\n",
    "\n",
    "predict(topic=\"physics\", context=\"The speed of light is 300,000 km/s.\", question=\"What is the speed of light?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3ac218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-13T20:30:04.998384]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `topic` (str): \n",
      "2. `context` (str): \n",
      "3. `question` (str):\n",
      "Your output fields are:\n",
      "1. `answer` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## topic ## ]]\n",
      "{topic}\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Answer the question as an expert in the topic.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## topic ## ]]\n",
      "physics\n",
      "\n",
      "[[ ## context ## ]]\n",
      "The speed of light is 300,000 km/s.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the speed of light?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## answer ## ]]\n",
      "The speed of light is 300,000 kilometers per second (km/s).\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ad72fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Setting up an OpenAI model\n",
    "lm = dspy.LM('openai/gpt-5-mini',\n",
    "temperature=1, max_tokens=16000) # additional params\n",
    "\n",
    "# Configure globally\n",
    "lm(\"Hello\")\n",
    "dspy.configure(lm=lm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d87401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context engineering is the practice of designing and managing the information provided to AI models (prompts, system messages, memories, and retrieved data) to make their outputs accurate, relevant, and consistent.\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# String signature: input -> output\n",
    "signature = \"question -> answer\"\n",
    "\n",
    "# Use it in a module\n",
    "qa = dspy.Predict(signature)\n",
    "response = qa(question=\"What is context engineering? Give me a brief explanation in one line.\")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f6bae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,000 km/s\n",
      "0.95\n",
      "The context explicitly states the speed of light as \"300,000 km/s,\" so I use that value.\n"
     ]
    }
   ],
   "source": [
    "qa_types = dspy.Predict(\"context: list[str], question: str -> reasoning: str, answer: str, confidence: float\")\n",
    "\n",
    "response = qa_types(context=[\"The speed of light is 300,000 km/s.\", \"The speed of sound is 343 m/s.\"], question=\"What is the speed of light?\")\n",
    "print(response.answer)\n",
    "print(response.confidence)\n",
    "print(response.reasoning)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c2995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_types(context=[\"The speed of light is 300,000 km/s.\", \"The speed of sound is 343 m/s.\"], question=\"What is the speed of light multiplied by the speed of sound?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bacab650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.029 × 10^11 m^2/s^2 (102,900,000,000 m^2/s^2)\n",
      "0.95\n",
      "Convert both speeds to the same units. The speed of light given is 300,000 km/s = 300,000 × 1,000 m/s = 300,000,000 m/s. Multiply by the speed of sound 343 m/s:\n",
      "300,000,000 m/s × 343 m/s = 102,900,000,000 m^2/s^2 = 1.029 × 10^11 m^2/s^2.\n"
     ]
    }
   ],
   "source": [
    "print(response.answer)\n",
    "print(response.confidence)\n",
    "print(response.reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31934c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,000 km/s (approximately 3.0 × 10^8 m/s)\n",
      "0.95\n",
      "The provided context explicitly states \"The speed of light is 300,000 km/s.\" Converting units, 300,000 km/s = 300,000,000 m/s = 3.0 × 10^8 m/s.\n"
     ]
    }
   ],
   "source": [
    "class QASignature(dspy.Signature):\n",
    "    \"\"\"Answer questions based on provided context with reasoning and confidence.\"\"\"\n",
    "    \n",
    "    context: list[str] = dspy.InputField()\n",
    "    question: str = dspy.InputField()\n",
    "    reasoning: str = dspy.OutputField()\n",
    "    answer = dspy.OutputField()\n",
    "    confidence: float = dspy.OutputField()\n",
    "\n",
    "# Use the class-based signature\n",
    "qa_types_class = dspy.Predict(QASignature)\n",
    "\n",
    "response = qa_types_class(\n",
    "    context=[\"The speed of light is 300,000 km/s.\", \"The speed of sound is 343 m/s.\"],\n",
    "    question=\"What is the speed of light?\"\n",
    ")\n",
    "print(response.answer)\n",
    "print(response.confidence)\n",
    "print(response.reasoning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4d369be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 300,000 km/s (which is 3.0 × 10^8 m/s).\n",
      "Confidence: 1.0\n",
      "Reasoning: The provided context states the speed of light as \"300,000 km/s\". I'll report that value and include the equivalent in meters per second.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define a Pydantic model for structured output\n",
    "class AnswerWithConfidence(BaseModel):\n",
    "    answer: str = Field(description=\"Clear, concise answer to the question\")\n",
    "    confidence: float = Field(\n",
    "        description=\"Confidence score between 0 and 1\",\n",
    "        ge=0.0,\n",
    "        le=1.0\n",
    "    )\n",
    "\n",
    "class QASignature(dspy.Signature):\n",
    "    \"\"\"Answer questions based on provided context with reasoning and confidence.\"\"\"\n",
    "    \n",
    "    context: list[str] = dspy.InputField()\n",
    "    question: str = dspy.InputField()\n",
    "    reasoning: str = dspy.OutputField()\n",
    "    output: AnswerWithConfidence = dspy.OutputField()\n",
    "\n",
    "# Use the class-based signature\n",
    "qa_types_class = dspy.Predict(QASignature)\n",
    "\n",
    "response = qa_types_class(\n",
    "    context=[\"The speed of light is 300,000 km/s.\", \"The speed of sound is 343 m/s.\"],\n",
    "    question=\"What is the speed of light?\"\n",
    ")\n",
    "print(f\"Answer: {response.output.answer}\")\n",
    "print(f\"Confidence: {response.output.confidence}\")\n",
    "print(f\"Reasoning: {response.reasoning}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3af6fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiply 450 by 2: 450 + 450 = 900.\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "# Create a module with a signature\n",
    "module = dspy.ChainOfThought(\"question -> answer\")\n",
    "\n",
    "# Call it like a function\n",
    "result = module(question=\"What is 2 x 450?\")\n",
    "\n",
    "# Access outputs by name\n",
    "print(result.reasoning)\n",
    "print(result.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6227019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiply 450 by 2: 450 + 450 = 900.\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "class QAWithCoT(dspy.Signature):\n",
    "    question = dspy.InputField(desc=\"The question to answer.\")\n",
    "    reasoning = dspy.OutputField()\n",
    "    \n",
    "    answer = dspy.OutputField(desc=\"The final answer.\")\n",
    "\n",
    "qa_cot = dspy.Predict(QAWithCoT)\n",
    "\n",
    "response = qa_cot(question=\"What is 2 x 450?\")\n",
    "\n",
    "print(response.reasoning)\n",
    "print(response.answer)\n",
    "\n",
    "qa_cot_inline = dspy.ChainOfThought(\"question -> answer\")\n",
    "\n",
    "response_inline = qa_cot_inline(question=\"What is 2 x 450?\")\n",
    "\n",
    "print(response.reasoning)\n",
    "print(response.answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f402d0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Manual CoT Signature ===\n",
      "Reasoning: Multiply 450 by 2: 450 + 450 = 900.\n",
      "Answer: 900\n",
      "\n",
      "=== ChainOfThought Wrapper ===\n",
      "Reasoning: Multiply 450 by 2: 450 + 450 = 900.\n",
      "Answer: 900\n",
      "\n",
      "--- Signature Field Order Comparison ---\n",
      "Base signature fields: ['question', 'answer']\n",
      "Manual signature fields: ['question', 'reasoning', 'answer']\n",
      "ChainOfThought fields: ['question', 'reasoning', 'answer']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-23T02:01:27.613635]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str): The question to answer.\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str): The final answer.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `reasoning`, `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is 2 x 450?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "Multiply 450 by 2: 450 + 450 = 900.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "900\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-23T02:01:27.629254]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is 2 x 450?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "Multiply 450 by 2: 450 + 450 = 900.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "900\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.signatures import ensure_signature\n",
    "\n",
    "# --- 1. Define a manual signature with explicit reasoning ---\n",
    "class QAWithReasoning(dspy.Signature):\n",
    "    reasoning = dspy.OutputField(\n",
    "        # structured adapter ignores prefix visually, but CoT sets this:\n",
    "        prefix=\"Reasoning: Let's think step by step in order to\",\n",
    "        # slot placeholder, so adapter won't print prose:\n",
    "        desc=\"${reasoning}\"\n",
    "    )\n",
    "    question = dspy.InputField(desc=\"The question to answer.\")\n",
    "    answer = dspy.OutputField(desc=\"The final answer.\")\n",
    "\n",
    "qa_manual = dspy.Predict(QAWithReasoning)\n",
    "\n",
    "print(\"\\n=== Manual CoT Signature ===\")\n",
    "response_manual = qa_manual(question=\"What is 2 x 450?\")\n",
    "print(\"Reasoning:\", response_manual.reasoning)\n",
    "print(\"Answer:\", response_manual.answer)\n",
    "\n",
    "# --- 2. Use DSPy's built-in ChainOfThought wrapper ---\n",
    "qa_auto = dspy.ChainOfThought(\"question -> answer\")\n",
    "\n",
    "print(\"\\n=== ChainOfThought Wrapper ===\")\n",
    "response_auto = qa_auto(question=\"What is 2 x 450?\")\n",
    "print(\"Reasoning:\", response_auto.reasoning)\n",
    "print(\"Answer:\", response_auto.answer)\n",
    "\n",
    "# --- 3. Show the internal field orders to confirm equivalence ---\n",
    "base_sig = ensure_signature(\"question -> answer\")\n",
    "manual_sig = qa_manual.signature\n",
    "auto_sig = qa_auto.predict.signature  # extended signature from ChainOfThought\n",
    "\n",
    "print(\"\\n--- Signature Field Order Comparison ---\")\n",
    "print(\"Base signature fields:\", [f for f in base_sig.fields])\n",
    "print(\"Manual signature fields:\", [f for f in manual_sig.fields])\n",
    "print(\"ChainOfThought fields:\", [f for f in auto_sig.fields])\n",
    "\n",
    "dspy.inspect_history(n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8390aba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's sunny in Tokyo, about 75°F (≈24°C).\n",
      "Tool calls made: {'thought_0': \"I'll fetch the current weather for Tokyo using the get_weather tool.\", 'tool_name_0': 'get_weather', 'tool_args_0': {'city': 'Tokyo'}, 'observation_0': 'The weather in Tokyo is sunny and 75°F', 'thought_1': \"I have the current weather for Tokyo: sunny and 75°F. I'll finish and provide that as the answer.\", 'tool_name_1': 'finish', 'tool_args_1': {}, 'observation_1': 'Completed.'}\n"
     ]
    }
   ],
   "source": [
    "# Define your tools as functions\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    # In a real implementation, this would call a weather API\n",
    "    return f\"The weather in {city} is sunny and 75°F\"\n",
    "\n",
    "# Create a ReAct agent\n",
    "react_agent = dspy.ReAct(\n",
    "    signature=\"question -> answer\",\n",
    "    tools=[get_weather],\n",
    "    max_iters=5\n",
    ")\n",
    "\n",
    "# Use the agent\n",
    "result = react_agent(question=\"What's the weather like in Tokyo?\")\n",
    "print(result.answer)\n",
    "print(\"Tool calls made:\", result.trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db80c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-23T01:44:53.449067]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str): The question to answer.\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str): The final answer.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `reasoning`, `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is 2 x 450?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "Multiply 450 by 2: 450 + 450 = 900.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "900\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-23T01:44:54.926590]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is 2 x 450?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "Multiply 450 by 2: 450 + 450 = 900.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "900\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeed3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class ToolSignature(dspy.Signature):\n",
    "    \"\"\"Signature for manual tool handling.\"\"\"\n",
    "    question: str = dspy.InputField()\n",
    "    tools: list[dspy.Tool] = dspy.InputField()\n",
    "    outputs: dspy.ToolCalls = dspy.OutputField()\n",
    "\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Get weather information for a city.\"\"\"\n",
    "    return f\"The weather in {city} is sunny\"\n",
    "\n",
    "\n",
    "# Create tool instances\n",
    "tools = {\n",
    "    \"weather\": dspy.Tool(weather),\n",
    "}\n",
    "\n",
    "# Create predictor\n",
    "predictor = dspy.Predict(ToolSignature)\n",
    "\n",
    "# Make a prediction\n",
    "response = predictor(\n",
    "    question=\"What's the weather in Tokyo?\",\n",
    "    tools=list(tools.values())\n",
    ")\n",
    "\n",
    "# Execute the tool calls\n",
    "for call in response.outputs.tool_calls:\n",
    "    # Execute the tool call\n",
    "    result = call.execute()\n",
    "    print(f\"Tool: {call.name}\")\n",
    "    print(f\"Args: {call.args}\")\n",
    "    print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd6fd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-23T14:32:04.394731]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (list[str]): Relevant context retrieved from our database\n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str): \n",
      "3. `confidence` (float):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## confidence ## ]]\n",
      "{confidence}        # note: the value you produce must be a single float value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Answer questions based on provided context with reasoning and confidence.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[\"The speed of light is 300,000 km/s.\", \"The speed of sound is 343 m/s.\"]\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the speed of light?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, then `[[ ## confidence ## ]]` (must be formatted as a valid Python float), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The context provided states that \"The speed of light is 300,000 km/s.\" This directly answers the question about the speed of light.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "300,000 km/s\n",
      "\n",
      "[[ ## confidence ## ]]\n",
      "1.0\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "dspy.configure(lm=dspy.LM(model=\"gpt-4o-mini\"))\n",
    "\n",
    "class QASignature(dspy.Signature):\n",
    "    \"\"\"Answer questions based on provided context with reasoning and confidence.\"\"\"\n",
    "    context: list[str] = dspy.InputField(desc=\"Relevant context retrieved from our database\")\n",
    "    question = dspy.InputField()\n",
    "    reasoning = dspy.OutputField()\n",
    "    answer = dspy.OutputField()\n",
    "    confidence: float = dspy.OutputField()\n",
    "\n",
    "qa_types_class = dspy.Predict(QASignature)\n",
    "\n",
    "response = qa_types_class(\n",
    "    context=[\"The speed of light is 300,000 km/s.\", \"The speed of sound is 343 m/s.\"],\n",
    "    question=\"What is the speed of light?\")\n",
    "\n",
    "dspy.settings.lm.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b29c8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='The capital of France is Paris.'\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Make a simple Q&A signature\n",
    "class QASignature(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField()\n",
    "\n",
    "# Create a module with a signature\n",
    "module = dspy.Predict(QASignature)\n",
    "\n",
    "module(question=\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c4eb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    answer='The capital of France is Paris.'\n",
      ")\n",
      "Prediction(\n",
      "    reasoning=\"Paris became the capital of France due to a combination of historical, geographical, and political factors. Historically, Paris was established as a significant settlement by the Parisii tribe in the 3rd century BC and later became the center of the Frankish kingdom under Clovis I in the 5th century. Its strategic location along the Seine River facilitated trade and communication, making it an attractive site for governance.\\n\\nGeopolitically, the consolidation of power by the Capetian dynasty in the 10th century further solidified Paris's status as the capital. The Capetians chose Paris as their seat of power, which allowed them to exert control over the surrounding regions. The city's growth was also influenced by its role in the development of the French state, particularly during the medieval period when it became a hub for culture, education, and politics.\\n\\nThe influence of Paris as the capital has led to significant centralization in France. The French monarchy and later the Republic centralized administrative functions in Paris, which became synonymous with national identity. This centralization has often marginalized regional identities and governance, leading to tensions between Paris and other regions. The focus on Paris as the political and cultural heart of France has shaped national policies and resource distribution, reinforcing its dominance in French life.\",\n",
      "    answer='Paris became the capital of France due to its historical significance as a settlement, its strategic geographical location, and the consolidation of power by the Capetian dynasty. This centralization has influenced French governance by making Paris the focal point of political, cultural, and administrative life, often at the expense of regional identities and autonomy.'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "# Add a classifier to identify complex questions\n",
    "class ClassifySignature(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    complexity: Literal[\"simple\", \"complex\"] = dspy.OutputField()\n",
    "\n",
    "\n",
    "# Create a module that handles the router pipeline\n",
    "class SmartQA(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # inherits from dspy.Module\n",
    "\n",
    "        # Create three different modules in one\n",
    "        self.classify = dspy.Predict(ClassifySignature)\n",
    "        self.simple_qa = dspy.Predict(QASignature)\n",
    "        self.complex_qa = dspy.ChainOfThought(QASignature)\n",
    "\n",
    "    # The forward method runs when the module is called\n",
    "    def forward(self, question):\n",
    "        # Determine question complexity\n",
    "        classification = self.classify(question=question)\n",
    "\n",
    "        # Route to appropriate strategy\n",
    "        if classification.complexity == \"simple\":\n",
    "            return self.simple_qa(question=question)\n",
    "        else:\n",
    "            return self.complex_qa(question=question)\n",
    "\n",
    "# Create the module\n",
    "smart_qa = SmartQA()\n",
    "\n",
    "# Use the module like a function\n",
    "response = smart_qa(question=\"What is the capital of France?\")\n",
    "print(response)\n",
    "\n",
    "smart_response = smart_qa(question=\"Explain the historical and geopolitical factors that led to Paris becoming the capital of France, and how this has influenced French centralization.\")\n",
    "print(smart_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d95c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example({'question': 'What is the capital of France?', 'context': 'France is a country in Western Europe. Its capital is Paris, which is known for its art, fashion, gastronomy and culture.', 'answer': 'Paris'}) (input_keys={'context', 'question'}),\n",
       " Example({'question': 'What is the speed of light?', 'context': 'The speed of light in a vacuum is approximately 299,792 kilometers per second, often rounded to 300,000 km/s.', 'answer': '300,000 kilometers per second'}) (input_keys={'context', 'question'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = [\n",
    "    {\n",
    "        \"question\": \"What is the capital of France?\",\n",
    "        \"context\": \"France is a country in Western Europe. Its capital is Paris, which is known for its art, fashion, gastronomy and culture.\",\n",
    "        \"answer\": \"Paris\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the speed of light?\",\n",
    "        \"context\": \"The speed of light in a vacuum is approximately 299,792 kilometers per second, often rounded to 300,000 km/s.\",\n",
    "        \"answer\": \"300,000 kilometers per second\"\n",
    "    }\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    dspy.Example(question=item[\"question\"], \n",
    "    context=item[\"context\"], \n",
    "    answer=item[\"answer\"]).with_inputs(\"question\", \"context\")\n",
    "    for item in dataset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    dspy.Example(\n",
    "        question=\"What is the capital of France?\",\n",
    "        context=\"France is a country in Western Europe. Its capital is Paris, which is known for its art, fashion, gastronomy and culture.\",\n",
    "        answer=\"Paris\"\n",
    "    ).with_inputs(\"question\", \"context\"),\n",
    "    dspy.Example(\n",
    "        question=\"What is the speed of light?\",\n",
    "        context=\"The speed of light in a vacuum is approximately 299,792 kilometers per second, often rounded to 300,000 km/s.\",\n",
    "        answer=\"300,000 km/s\"\n",
    "    ).with_inputs(\"question\", \"context\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc925da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_metric(example, pred, trace=None):\n",
    "    \"\"\"Returns a float between 0.0 and 1.0 based on word overlap, or boolean if trace is provided.\"\"\"\n",
    "    gold_words = example.answer.lower().split()\n",
    "    pred_words = set(pred.answer.lower().split())\n",
    "    \n",
    "    if len(gold_words) == 0:\n",
    "        return False if trace is not None else 0.0\n",
    "    \n",
    "    # Count how many words in gold are in pred\n",
    "    matching_words = sum(1 for word in gold_words if word in pred_words)\n",
    "    score = matching_words / len(gold_words)\n",
    "\n",
    "    # Return boolean during optimization if score is > 0.75\n",
    "    if trace is not None:\n",
    "        return score > 0.75\n",
    "\n",
    "    # Otherwise return the score\n",
    "    return score\n",
    "\n",
    "# Test the metric\n",
    "score = qa_metric(examples[0], dspy.Prediction(answer=\"Paris\"))\n",
    "print(f\"Metric score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation of the difference between trainset, devset (valset), and testset\n",
    "\n",
    "\"\"\"\n",
    "- **Train set**: The subset of data used to train machine learning models. The model learns patterns and fits parameters using only this data.\n",
    "\n",
    "- **Dev set / Validation set (valset)**: The subset of data used to tune hyperparameters, choose models, or stop training (early stopping). This set helps you check the model's performance during training and select the best version, but it's not directly used to update the model's parameters.\n",
    "\n",
    "- **Test set**: The reserved data used to assess the final performance of the model after all training and tuning are complete. This provides an unbiased estimate of the model's ability to generalize to new, unseen data.\n",
    "\n",
    "Often, \"dev set\" and \"validation set\" mean the same thing and are used interchangeably.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ae6e291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 0\n",
      "Val set: 1\n",
      "Test set: 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Split: 30% train, 50% val, 20% test\n",
    "random.shuffle(examples)\n",
    "\n",
    "n = len(examples)\n",
    "n_train = int(0.3 * n)\n",
    "n_val = int(0.5 * n)\n",
    "\n",
    "trainset = examples[:n_train]\n",
    "valset = examples[n_train:n_train + n_val]\n",
    "testset = examples[n_train + n_val:]\n",
    "\n",
    "print(\"Train set:\", len(trainset))\n",
    "print(\"Val set:\", len(valset))\n",
    "print(\"Test set:\", len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Make a simple Q&A signature\n",
    "class QASignature(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField()\n",
    "\n",
    "# Create a module with a signature\n",
    "module = dspy.Predict(QASignature)\n",
    "\n",
    "result = module(question=\"What is the capital of France?\")\n",
    "print(result.answer)\n",
    "\n",
    "\n",
    "dataset = [\n",
    "    {\n",
    "        \"question\": \"What is the capital of France?\",\n",
    "        \"context\": \"France is a country in Western Europe. Its capital is Paris, which is known for its art, fashion, gastronomy and culture.\",\n",
    "        \"answer\": \"Paris\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the speed of light?\",\n",
    "        \"context\": \"The speed of light in a vacuum is approximately 299,792 kilometers per second, often rounded to 300,000 km/s.\",\n",
    "        \"answer\": \"300,000 km/s\"\n",
    "    }\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    dspy.Example(\n",
    "question=item[\"question\"], \n",
    "    \tcontext=item[\"context\"], \n",
    "    \tanswer=item[\"answer\"]\n",
    ").with_inputs(\"question\", \"context\")\n",
    "    for item in dataset\n",
    "]\n",
    "\n",
    "scores = []\n",
    "for example in examples:\n",
    "    result = module(question=example.question)\n",
    "    score = qa_metric(example, result)\n",
    "    scores.append(score)\n",
    "\n",
    "print(f\"Average score: {sum(scores) / len(scores)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
